{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd062a17",
   "metadata": {},
   "source": [
    "DEFINICIONES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46d4ebd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests.exceptions import RequestException\n",
    "import requests, pandas as pd, os, time\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "\n",
    "os.system(\"cls\")\n",
    "\n",
    "url = 'https://books.toscrape.com/'\n",
    "head = {\n",
    "    'User-Agent':'MiSraper/1.0 (oscaaraujo96@gmail.com)'\n",
    "}\n",
    "\n",
    "session = requests.session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005a8fde",
   "metadata": {},
   "source": [
    "FUNCIONES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f643cbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Realiza la conexión y get de forma segura y con reintentos\n",
    "def safe_get (url, intentos=3, delay=2):\n",
    "    for i in range(intentos):\n",
    "        try:\n",
    "            respuesta = session.get(url, headers=head, timeout=10)\n",
    "            respuesta.raise_for_status()\n",
    "            return respuesta\n",
    "        except RequestException as e:\n",
    "            print(f\"Intento {i+1}] Error en {url}: {e}\")\n",
    "            time.sleep(delay)\n",
    "    return None\n",
    "\n",
    "\n",
    "###Se obtiene las categorias del sitio\n",
    "def obtener_categorias (url_base):\n",
    "\n",
    "    respuesta = safe_get(url_base)\n",
    "    soup = BeautifulSoup(respuesta.text, \"html.parser\")\n",
    "    list_category = soup.select_one(\"ul.nav\")\n",
    "    data_category = list_category.select(\"ul li a\")\n",
    "\n",
    "    url_categorias = {}\n",
    "    for link in data_category[1:]:\n",
    "        url_category = link[\"href\"]\n",
    "        url_categorias[link.get_text(strip=True)] = urljoin(url, url_category)\n",
    "    \n",
    "    return url_categorias\n",
    "\n",
    "\n",
    "###Scrap de una categoría\n",
    "def scrap_categorie (url_categoria, nombre_categoria):\n",
    "    all_books = []\n",
    "    while True:\n",
    "        resp = safe_get(url_categoria)\n",
    "        soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "        libros = soup.select(\"article.product_pod\")\n",
    "        for libro in libros:\n",
    "            titulo = libro.select_one(\"h3 a\")[\"title\"]\n",
    "            tipo_moneda ,value = libro.select_one(\"p.price_color\").text.split(\"£\", 1)\n",
    "\n",
    "            _, rating_get = libro.select_one(\"p.star-rating\").get(\"class\", [])\n",
    "            rating_map = {\"One\":1, \"Two\":2, \"Three\":3, \"Four\":4, \"Five\":5}\n",
    "            rating = 0\n",
    "            if rating_get in rating_map:\n",
    "                rating += rating_map[rating_get]\n",
    "\n",
    "            all_books.append({\"titulo\":titulo, \"precio\":float(value), \"puntuacion\":rating, \"categoria\":nombre_categoria})\n",
    "        \n",
    "        #buscar boton next\n",
    "        next_tag = soup.select_one(\"li.next a\")\n",
    "        if next_tag:\n",
    "            next_url = urljoin(url_categoria, next_tag[\"href\"])\n",
    "            url_categoria = next_url\n",
    "            time.sleep(0.3)\n",
    "        else:\n",
    "            break\n",
    "    return all_books\n",
    "\n",
    "####Sracp de todas las categorías\n",
    "def scrap_all_categories(url_categorias):\n",
    "    for name,dir_categoria in url_categorias.items():\n",
    "        scrap_categorie(dir_categoria,name)\n",
    "        print(f\"Categoria trabajada {name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1266523e",
   "metadata": {},
   "source": [
    "Realizamos el scraping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94451ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intento 1] Error en https://books.toscrape.com/: HTTPSConnectionPool(host='books.toscrape.com', port=443): Read timed out. (read timeout=10)\n",
      "Categoria trabajada Travel\n",
      "Categoria trabajada Mystery\n",
      "Categoria trabajada Historical Fiction\n",
      "Categoria trabajada Sequential Art\n",
      "Categoria trabajada Classics\n",
      "Categoria trabajada Philosophy\n",
      "Categoria trabajada Romance\n",
      "Categoria trabajada Womens Fiction\n",
      "Categoria trabajada Fiction\n",
      "Categoria trabajada Childrens\n",
      "Categoria trabajada Religion\n",
      "Categoria trabajada Nonfiction\n",
      "Categoria trabajada Music\n",
      "Categoria trabajada Default\n",
      "Categoria trabajada Science Fiction\n",
      "Categoria trabajada Sports and Games\n"
     ]
    }
   ],
   "source": [
    "url_categorias = obtener_categorias(url)\n",
    "\n",
    "scrap_all_categories(url_categorias)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
